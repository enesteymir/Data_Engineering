{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89f99976-3681-44e1-8942-fb9e2ed6ec36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import urllib.parse\n",
    "from aws_requests_auth.aws_auth import AWSRequestsAuth\n",
    "\n",
    "\n",
    "dbutils.widgets.text('start', '')\n",
    "dbutils.widgets.text('end', '')\n",
    "\n",
    "start = dbutils.widgets.get('start')\n",
    "end = dbutils.widgets.get('end')\n",
    "\n",
    "\n",
    "A_KEY = 'AKIA........2GE'\n",
    "A_SECRET = 'Kz54............x'\n",
    "ARN = 'arn:aws:iam::466....17:role/ebzsellingapiRole'\n",
    "\n",
    "\n",
    "C_KEY = 'amzn1.application-oa2-client.c89........e69f'\n",
    "C_SECRET_KEY = 'amzn1.oa2-cs.v1.cbda92927ac...............a781a'\n",
    "C_REFRESH_TOKEN = 'Atzr|IwEBIDuBz3QTjlBJH8.......yGrzABTI-Lx2L-HM'\n",
    "\n",
    "\n",
    "MARKETPLACE_IDS = [\n",
    "                'A1PA6795UKMFR9',  # DE\n",
    "                'A1F83G8C2ARO7P',  # UK\n",
    "                'A13V1IB3VIYZZH',  # FR  \n",
    "                'A1RKKUPIHCS9HS',  # ES\n",
    "                'APJ6JRA9NG5V4'    # IT\n",
    "                ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a4449e5-283d-421f-b3dd-6c71d232a3fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- Authentication Functions ---\n",
    "\n",
    "def get_access_token():\n",
    "    \"\"\"Gets the LWA access token using the refresh token.\"\"\"\n",
    "    global C_KEY, C_SECRET_KEY, C_REFRESH_TOKEN\n",
    "    r = requests.post(f\"https://api.amazon.com/auth/o2/token\", data={\n",
    "                        \"grant_type\":\"refresh_token\",\n",
    "                        \"refresh_token\":C_REFRESH_TOKEN,\n",
    "                        \"client_id\": C_KEY,\n",
    "                        \"client_secret\": C_SECRET_KEY\n",
    "                        })\n",
    "    return r.json()['access_token']\n",
    "\n",
    "\n",
    "def assume_role():\n",
    "    \"\"\"Assumes the IAM role and gets temporary AWS security credentials.\"\"\"\n",
    "    r = requests.get(f\"https://sts.amazonaws.com?Version=2011-06-15&Action=AssumeRole&RoleSessionName=Test&RoleArn={ARN}&DurationSeconds=3600\",\n",
    "                    auth=AWS4Auth(A_KEY, A_SECRET, 'us-east-1', 'sts'))\n",
    "    \n",
    "    # Simple regex parsing (as in original code)\n",
    "    access_key = re.findall('<AccessKeyId>(.+)</AccessKeyId>', r.text)[0]\n",
    "    secret_key = re.findall('<SecretAccessKey>(.+)</SecretAccessKey>', r.text)[0]\n",
    "    session_token = re.findall('<SessionToken>(.+)</SessionToken>', r.text)[0]\n",
    "    \n",
    "    return (access_key, secret_key, session_token)\n",
    "\n",
    "\n",
    "def get_keys():\n",
    "    \"\"\"Fetches both LWA and AWS temporary credentials.\"\"\"\n",
    "    return get_access_token(), *assume_role()\n",
    "\n",
    "\n",
    "access_token, access_key, secret_key, session_token = get_keys()\n",
    "print('Got the access token : ' , access_token)\n",
    "\n",
    "\n",
    "\n",
    "def refresh_credentials_if_needed(last_refresh_time, token_refresh_interval=1800):\n",
    "    \"\"\"\n",
    "    Check if credentials need refresh based on elapsed time\n",
    "    \n",
    "    Args:\n",
    "        last_refresh_time: timestamp of last token refresh\n",
    "        token_refresh_interval: refresh interval in seconds (default: 1800 = 30 minutes)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (access_token, access_key, secret_key, session_token, new_refresh_time)\n",
    "    \"\"\"\n",
    "    current_time = time.time()\n",
    "    elapsed_since_refresh = current_time - last_refresh_time\n",
    "    \n",
    "    if elapsed_since_refresh >= token_refresh_interval:\n",
    "        print(f\"\\n\uD83D\uDD04 Refreshing credentials (elapsed: {elapsed_since_refresh/60:.1f} minutes)...\")\n",
    "        access_token, access_key, secret_key, session_token = get_keys()\n",
    "        print(f\"✅ Credentials refreshed successfully\")\n",
    "        return access_token, access_key, secret_key, session_token, current_time\n",
    "    \n",
    "    # Return None to indicate no refresh needed\n",
    "    return None, None, None, None, last_refresh_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56913994-c020-4600-ba2a-3873d81876c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a date range list\n",
    "start_date = datetime.strptime(start, \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(end, \"%Y-%m-%d\")\n",
    "\n",
    "date_list = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "date_list = date_list.strftime(\"%Y-%m-%d\")\n",
    "print(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcaed937-87e9-4c96-8a81-25b7cbc9e9d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Connection details to Azure SQL Database\n",
    "connection_string = f\"jdbc:sqlserver://ebzreporting.database.windows.net:1433;database=<databasename>;user=<username>@ebzreporting;password=<password>;encrypt=true;trustServerCertificate=false;hostNameInCertificate=*.database.windows.net;loginTimeout=30;\"\n",
    "\n",
    "SP_API_REGION = \"eu-west-1\"\n",
    "SP_API_HOST = \"sellingpartnerapi-eu.amazon.com\"\n",
    "REQUESTS_PER_SECOND = 0.5\n",
    "DELAY_BETWEEN_REQUESTS = 1 / REQUESTS_PER_SECOND  # 2 seconds between requests\n",
    "MAX_RETRIES = 3\n",
    "RETRY_DELAY = 60  # Wait 60 seconds before retrying after quota exceeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "111172df-e8ee-44df-b7ab-378b8c93b694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_order_items_with_pagination(order_id, access_token, access_key, secret_key, session_token, retry_count=0):\n",
    "    \"\"\"\n",
    "    Fetch all order items for an order, handling pagination if needed\n",
    "    Includes rate limiting and retry logic for quota errors\n",
    "    \"\"\"\n",
    "    global SP_API_REGION, SP_API_HOST, DELAY_BETWEEN_REQUESTS, MAX_RETRIES, RETRY_DELAY\n",
    "    \n",
    "    all_items = []\n",
    "    next_token = None\n",
    "    page = 1\n",
    "    \n",
    "    while True:\n",
    "        if next_token is None:\n",
    "            rel_url = f\"/orders/v0/orders/{order_id}/orderItems\"\n",
    "        else:\n",
    "            rel_url = f\"/orders/v0/orders/{order_id}/orderItems?NextToken={next_token}\"\n",
    "        \n",
    "        url = f\"https://{SP_API_HOST}{rel_url}\"\n",
    "        \n",
    "        headers = {\n",
    "            'x-amz-access-token': access_token,\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        \n",
    "        auth = AWS4Auth(\n",
    "            access_key,\n",
    "            secret_key,\n",
    "            SP_API_REGION,\n",
    "            'execute-api',\n",
    "            session_token=session_token\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, auth=auth)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            \n",
    "            # Check for quota exceeded error even in successful response\n",
    "            if 'errors' in result:\n",
    "                for error in result['errors']:\n",
    "                    if error.get('code') == 'QuotaExceeded':\n",
    "                        if retry_count < MAX_RETRIES:\n",
    "                            print(f\"  ⚠️ Quota exceeded for order {order_id}. Waiting {RETRY_DELAY} seconds before retry {retry_count + 1}/{MAX_RETRIES}...\")\n",
    "                            time.sleep(RETRY_DELAY)\n",
    "                            return get_order_items_with_pagination(order_id, access_token, access_key, secret_key, session_token, retry_count + 1)\n",
    "                        else:\n",
    "                            return {\n",
    "                                \"orderId\": order_id,\n",
    "                                \"status\": \"error\",\n",
    "                                \"error\": f\"QuotaExceeded after {MAX_RETRIES} retries\",\n",
    "                                \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "                            }\n",
    "            \n",
    "            # Collect items from this page\n",
    "            if 'payload' in result and 'OrderItems' in result['payload']:\n",
    "                all_items.extend(result['payload']['OrderItems'])\n",
    "            \n",
    "            # Check for next page\n",
    "            if 'payload' in result and 'NextToken' in result['payload']:\n",
    "                next_token = result['payload']['NextToken']\n",
    "                page += 1\n",
    "                # Add delay between paginated requests\n",
    "                time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "            else:\n",
    "                # No more pages\n",
    "                break\n",
    "                \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            error_detail = str(e)\n",
    "            try:\n",
    "                if hasattr(e, 'response') and e.response is not None:\n",
    "                    error_detail = e.response.text\n",
    "                    # Check if it's a quota error\n",
    "                    if 'QuotaExceeded' in error_detail and retry_count < MAX_RETRIES:\n",
    "                        print(f\"  ⚠️ Quota exceeded for order {order_id}. Waiting {RETRY_DELAY} seconds before retry {retry_count + 1}/{MAX_RETRIES}...\")\n",
    "                        time.sleep(RETRY_DELAY)\n",
    "                        return get_order_items_with_pagination(order_id, access_token, access_key, secret_key, session_token, retry_count + 1)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            return {\n",
    "                \"orderId\": order_id,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": error_detail,\n",
    "                \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "            }\n",
    "    \n",
    "    return {\n",
    "        \"orderId\": order_id,\n",
    "        \"status\": \"success\",\n",
    "        \"data\": {\n",
    "            \"payload\": {\n",
    "                \"OrderItems\": all_items,\n",
    "                \"TotalPages\": page\n",
    "            }\n",
    "        },\n",
    "        \"timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3a567d0-f9f9-419d-b553-f820a49d219e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/amazon-order-items already mounted\n"
     ]
    }
   ],
   "source": [
    "storageAccountName = \"blobinventory\"\n",
    "containerName = \"amazon-order-items\"\n",
    "sas = \"sp=racwdli&st=2025-11-14T13:59:29Z&se=2029-04-30T22:14:29Z&spr=https&sv=2024-11-0............Kp18yVE%3D\"\n",
    "config = \"fs.azure.sas.\" + containerName + \".\" + storageAccountName + \".blob.core.windows.net\"\n",
    "mount_point = \"/mnt/\" + containerName\n",
    "\n",
    "# Only mount if not already mounted\n",
    "if not any(mount.mountPoint == mount_point for mount in dbutils.fs.mounts()):\n",
    "    dbutils.fs.mount(\n",
    "        source = f\"wasbs://{containerName}@{storageAccountName}.blob.core.windows.net\",\n",
    "        mount_point = mount_point,\n",
    "        extra_configs = {config: sas}\n",
    "    )\n",
    "    print(f\"Mounted {mount_point}\")\n",
    "else:\n",
    "    print(f\"{mount_point} already mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29e9f1ba-121e-4833-8923-69417b921cb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 489 orders for 2025-11-01\nProgress for 2025-11-01: 20/489 orders | Elapsed: 0.7min | ETA: 15.6min | Token age: 0.7min\nProgress for 2025-11-01: 40/489 orders | Elapsed: 1.4min | ETA: 15.3min | Token age: 1.4min\nProgress for 2025-11-01: 60/489 orders | Elapsed: 2.1min | ETA: 14.8min | Token age: 2.1min\n"
     ]
    }
   ],
   "source": [
    "# Token refresh configuration\n",
    "TOKEN_REFRESH_INTERVAL = 30 * 60 \n",
    "last_token_refresh_time = time.time()\n",
    "overall_start_time = time.time()\n",
    "\n",
    "# Loop the dates and get the order items for each date from the order table\n",
    "for purchase_date in date_list:\n",
    "    query = f\"\"\"\n",
    "        (\n",
    "            SELECT DISTINCT order_id \n",
    "            FROM logistics_ft_orders \n",
    "            WHERE purchase_date = '{purchase_date}'\n",
    "        ) AS orders_filtered\n",
    "        \"\"\"\n",
    "\n",
    "    df_orders = spark.read.jdbc(\n",
    "        url=connection_string,\n",
    "        table=query\n",
    "    )\n",
    "\n",
    "    order_count = df_orders.count()\n",
    "    print(f\"Found {order_count} orders for {purchase_date}\")\n",
    "\n",
    "    if order_count == 0:\n",
    "        print(f\"⚠️ No orders found for {purchase_date}, skipping...\\n\")\n",
    "        continue\n",
    "\n",
    "    order_ids = [row.order_id for row in df_orders.select(\"order_id\").collect()]\n",
    "\n",
    "    all_order_items = []\n",
    "    failed_orders = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for idx, order_id in enumerate(order_ids):\n",
    "        # Check if we need to refresh credentials\n",
    "        new_access_token, new_access_key, new_secret_key, new_session_token, last_token_refresh_time = refresh_credentials_if_needed(last_token_refresh_time, TOKEN_REFRESH_INTERVAL)\n",
    "        \n",
    "        if new_access_token is not None:\n",
    "            # Update credentials\n",
    "            access_token = new_access_token\n",
    "            access_key = new_access_key\n",
    "            secret_key = new_secret_key\n",
    "            session_token = new_session_token\n",
    "        \n",
    "        if (idx + 1) % 20 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            elapsed_total = time.time() - overall_start_time\n",
    "            time_since_last_refresh = time.time() - last_token_refresh_time\n",
    "            avg_time_per_order = elapsed / (idx + 1)\n",
    "            remaining_orders = len(order_ids) - (idx + 1)\n",
    "            eta_seconds = remaining_orders * avg_time_per_order\n",
    "            \n",
    "            print(f\"Progress for {purchase_date}: {idx + 1}/{len(order_ids)} orders | \"\n",
    "                  f\"Elapsed: {elapsed/60:.1f}min | ETA: {eta_seconds/60:.1f}min | \"\n",
    "                  f\"Token age: {time_since_last_refresh/60:.1f}min\")\n",
    "        \n",
    "        # Use pagination-aware function with rate limiting\n",
    "        result = get_order_items_with_pagination(\n",
    "            order_id, \n",
    "            access_token, \n",
    "            access_key, \n",
    "            secret_key, \n",
    "            session_token\n",
    "        )\n",
    "        \n",
    "        # Add purchase_date to the result\n",
    "        result[\"purchase_date\"] = purchase_date\n",
    "        \n",
    "        all_order_items.append(result)\n",
    "        \n",
    "        if result[\"status\"] == \"error\":\n",
    "            failed_orders.append(order_id)\n",
    "            print(f\"Error for order {order_id} in {purchase_date}: {result['error'][:100]}\")\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        time.sleep(DELAY_BETWEEN_REQUESTS)\n",
    "\n",
    "    # Save data to DBFS\n",
    "    fileName = f'{purchase_date}_order_items'\n",
    "    dbfs_path = f'dbfs:/mnt/{containerName}/orders_items/{fileName}.json'\n",
    "    dbutils.fs.put(dbfs_path, json.dumps(all_order_items, indent=2), overwrite=True)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"✅ {fileName} is written. ({len(order_ids)} orders, {total_time/60:.1f}min, {len(failed_orders)} failed)\\n\")\n",
    "\n",
    "print(f\"\\n\uD83C\uDF89 All dates processed! Total time: {(time.time() - overall_start_time)/60:.1f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "API_Amazon_Order_Items",
   "widgets": {
    "end": {
     "currentValue": "2025-11-18",
     "nuid": "135bb2e4-da69-439d-8ffd-25338ee636b0",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "end",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "end",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "start": {
     "currentValue": "2025-11-01",
     "nuid": "d1e34662-405f-492d-9c11-03dad2ea7eb7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "start",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "start",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}