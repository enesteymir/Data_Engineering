{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03510e27-ccae-496a-8137-4cb652bd4539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install s3fs --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43a13e31-c7e3-46d1-838f-915512773601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from datetime import timedelta, datetime \n",
    "from pyspark.sql.functions import lit, col, to_date, date_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85c08e92-9710-4524-a9e9-c9731b27275c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_path = \"s3://tracking-analytics/consents-export-parquet\"\n",
    "target_path = \"s3a://zalando-tracking/consents-export-delta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03e234d1-b8d9-42c9-964d-110a02deebcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StructType([StructField('browser-id', StringType(), True), StructField('client-id', StringType(), True), StructField('consents', ArrayType(StructType([StructField('action', StringType(), True), StructField('consentStatus', BooleanType(), True), StructField('dataProcessingService', StringType(), True), StructField('language', StringType(), True)]), True), True), StructField('created_at', StringType(), True), StructField('host', StringType(), True), StructField('updated_at', StringType(), True)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = spark.read.format(\"parquet\").load(f\"{source_path}/01-05-2024/\").schema\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77d50628-1dbb-43ac-b495-8b3977d61d24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get date list for specified range in required format\n",
    "def list_of_dates(start_date_str, end_date_str):\n",
    "\tstart_date_obj = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "\tend_date_obj = datetime.strptime(end_date_str, \"%Y-%m-%d\")\n",
    "\tdates_list = [ \n",
    "\t            (start_date_obj + timedelta(days=i)).strftime(\"%d-%m-%Y\")\n",
    "\t            for i in range((end_date_obj - start_date_obj).days + 1)\n",
    "\t            ] \n",
    "\treturn dates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6418409-9755-4542-ae04-d3fc87b07dd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "default_date = \"2023-01-01\"\n",
    "dbutils.widgets.text(\"start_date\", default_date)\n",
    "dbutils.widgets.text(\"end_date\", default_date)\n",
    "start_date = dbutils.widgets.get(\"start_date\")\n",
    "end_date = dbutils.widgets.get(\"end_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cae488c9-21cf-43ba-86be-ae6919549c88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "date_list = list_of_dates(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9207f84-2863-4a63-ae19-93040b5ac8cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted files for date: 2023-01-01\n"
     ]
    }
   ],
   "source": [
    "s3 = s3fs.S3FileSystem()\n",
    "\n",
    "# Loop through the dates\n",
    "for date_str in date_list:\n",
    "    try:\n",
    "        files = s3.ls(f\"{source_path}/{date_str}\")\n",
    "        combined_df: DataFrame = None  \n",
    "\n",
    "        for file in files:\n",
    "            file_name = file.split('/')[-1]\n",
    "        \n",
    "            parquet_df = (\n",
    "                spark.read\n",
    "                .format(\"parquet\")\n",
    "                .schema(schema)\n",
    "                .load(f\"{source_path}/{date_str}/{file_name}\")\n",
    "            )\n",
    "            \n",
    "            formatted_date_str = datetime.strptime(date_str, \"%d-%m-%Y\").strftime(\"%Y-%m-%d\")\n",
    "            parquet_df = parquet_df.withColumn(\"dt\", lit(formatted_date_str))\n",
    "            \n",
    "            # Combine DataFrames\n",
    "            if combined_df is None:\n",
    "                combined_df = parquet_df\n",
    "            else:\n",
    "                combined_df = combined_df.unionByName(parquet_df)\n",
    "\n",
    "        # If combined_df is not empty, write to Delta\n",
    "        if combined_df is not None:\n",
    "            (\n",
    "            combined_df.write\n",
    "                .format(\"delta\")\n",
    "                .mode(\"append\")\n",
    "                .partitionBy(\"dt\")\n",
    "                .save(target_path)\n",
    "            )\n",
    "            print(f\"Successfully converted files for date: {formatted_date_str}\")\n",
    "        else:\n",
    "            print(f\"No files found for date: {formatted_date_str}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing date {formatted_date_str}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "convert-parquet-to-delta",
   "widgets": {
    "end_date": {
     "currentValue": "2023-01-01",
     "nuid": "e7b52064-d040-41a5-9421-629388079d17",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2023-01-01",
      "label": null,
      "name": "end_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2023-01-01",
      "label": null,
      "name": "end_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "start_date": {
     "currentValue": "2023-01-01",
     "nuid": "9595dfa7-2e99-423c-a6b2-08eee319691c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "2023-01-01",
      "label": null,
      "name": "start_date",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "2023-01-01",
      "label": null,
      "name": "start_date",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
