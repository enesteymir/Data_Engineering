{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3de34722-f5a6-45ef-af62-cc916c6dde2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a dict in seperate py file called validation.py and define all the filter rules for each event such as below\n",
    "add_to_cart = {\n",
    "\n",
    "     \"event_name\"     : 'add_to_cart'\n",
    "\n",
    "    ,\"RequiredFields\" : '''         \n",
    "                    CASE WHEN content_group IS NULL THEN 'content_group is null'\n",
    "                        WHEN price IS NULL THEN 'price is null'\n",
    "                        ELSE 'Valid'\n",
    "                    END AS RequiredFieldsTest\n",
    "                '''\n",
    "    \n",
    "    ,\"StringFields\"   : '''\n",
    "                    CASE WHEN IsString(content_group) = FALSE THEN 'content_group is not string'\n",
    "                        WHEN IsString(initial_flow_id) = FALSE THEN 'initial_flow_id is not string'\n",
    "                        ELSE 'Valid'\n",
    "                    END AS StringFieldsTest\n",
    "                '''\n",
    "\n",
    "    ,\"IntegerFields\"  : '''         \n",
    "                CASE WHEN IsInteger(ga_session_id) = FALSE THEN 'ga_session_id is not integer'\n",
    "                    ELSE 'Valid'\n",
    "                END AS IntegerFieldsTest\n",
    "                '''\n",
    "\n",
    "    ,\"FloatFields\"    : '''\n",
    "                CASE WHEN IsFloat(price) = FALSE THEN 'price is not float'\n",
    "                ELSE 'Valid'\n",
    "                END AS FloatFieldsTest\n",
    "                '''\n",
    "\n",
    "    ,\"PseudonymizationFields\" : '''\n",
    "                CASE \n",
    "                    WHEN user_id IS NOT NULL \n",
    "                        AND user_id NOT LIKE 'pa.%' \n",
    "                        AND user_id != 'PSEUDONYMIZATION_NOT_ALLOWED_01' \n",
    "                    THEN 'user_id Not Pseudonimized'\n",
    "                    ELSE 'Valid'\n",
    "                END AS PseudonymizationTest\n",
    "                '''\n",
    "}\n",
    "\n",
    "add_to_wishlist = { '''\n",
    "                   .......\n",
    "                   '''\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "event_list = [\n",
    "                add_to_cart\n",
    "               ,add_to_wishlist\n",
    "            ]\n",
    "\n",
    "\n",
    "# Import this py file in main notebook\n",
    "from validations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b1a1b38-a40c-47f1-a993-242bf732cd49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install google-cloud-bigquery --quiet\n",
    "%pip install pandas-gbq --quiet\n",
    "%pip install google-auth --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7e4070e-7123-4f6e-a1f1-36ce3d96cbf0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.utils\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests as req\n",
    "import base64\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "import os\n",
    "from operator import and_, or_\n",
    "from functools import reduce\n",
    "\n",
    "# Import helper functions from py file\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3e30d72-f1fd-41a0-9f31-dbcd5796241e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get Service Account Credentials from Databricks Scope\n",
    "b64 = dbutils.secrets.get(scope=\"team-tracking-scope\", key=\"b64_databricks_eu@team-tracking\") \n",
    "creds = base64.b64decode(b64)\n",
    "key = json.loads(creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d8a35e-582b-4e5c-aa81-6d562662bc4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set Credentials for GCS : https://docs.databricks.com/en/connect/storage/gcs.html\n",
    "\n",
    "project_id = key[\"project_id\"]\n",
    "privateKeyId = key[\"private_key_id\"]\n",
    "privateKey = key[\"private_key\"]\n",
    "clientEmail = key[\"client_email\"]\n",
    "\n",
    "\n",
    "spark.conf.set(\"credentials\", b64)\n",
    "spark.conf.set(\"parentProject\", project_id)\n",
    "spark.conf.set(\"project\", project_id)\n",
    "\n",
    "\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.private.key.id\", privateKeyId)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.private.key\", privateKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.email\", clientEmail)\n",
    "\n",
    "\n",
    "temporaryGcsBucket = 'tracking-eu-spark-bigquery-temp'\n",
    "materializationDataset = \"spark_staging_EU\" ## GCS Bucket for temporary data storage\n",
    "\n",
    "\n",
    "service_account_b64 = key\n",
    "credentials = service_account.Credentials.from_service_account_info(service_account_b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ec01278-bded-449f-968c-5c35f506d84b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-07-18', '2024-07-18']\n2024-07-18 2024-07-18\n20240718 20240718\n"
     ]
    }
   ],
   "source": [
    "# Get dates from widgets. If it's not set, then process data for yesterday\n",
    "try:\n",
    "    start = datetime.strptime(dbutils.widgets.get(\"startDate\"), \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(dbutils.widgets.get(\"endDate\"), \"%Y-%m-%d\")\n",
    "except:\n",
    "    # start=datetime.strptime('2022-09-01','%Y-%m-%d')\n",
    "    # end=datetime.strptime('2022-09-01','%Y-%m-%d')\n",
    "    start = datetime.today() - timedelta(days=1)\n",
    "    end = datetime.today() - timedelta(days=1)\n",
    "\n",
    "\n",
    "yesterday = datetime.today() - timedelta(days=1)\n",
    "end_utc_adjusted = end + timedelta(days=1)\n",
    "\n",
    "# Prepare date filters for GA4 query\n",
    "startDate = start.strftime(\"%Y-%m-%d\")\n",
    "endDate = end.strftime(\"%Y-%m-%d\")\n",
    "startDateBQ = start.strftime(\"%Y%m%d\")\n",
    "\n",
    "if yesterday.date() == end.date():\n",
    "    endDateBQ = end.strftime(\"%Y%m%d\")\n",
    "    time_boundary = \"EXTRACT(hour FROM TIMESTAMP_MICROS(event_timestamp))<22\"\n",
    "else:\n",
    "    endDateBQ = end_utc_adjusted.strftime(\"%Y%m%d\")\n",
    "    time_boundary = \"1=1\"\n",
    "\n",
    "\n",
    "dates = [startDate, endDate]\n",
    "#dates_regx = generate_json_list(startDate, endDate)\n",
    "print(dates)\n",
    "print(startDate, endDate)\n",
    "print(startDateBQ, endDateBQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8e7a0b68-47d1-4f94-a31f-bfa6222c33a6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create DF for unvalid events\n",
    "GA4_schema = ( StructType()\n",
    "             .add('event_name', StringType())\n",
    "             .add('dt', StringType()) \n",
    "             .add('event_timestamp', LongType())\n",
    "             .add('event_previous_timestamp', LongType())\n",
    "             .add('event_server_timestamp_offset', LongType())\n",
    "             .add('event_value_in_usd', DoubleType())\n",
    "             .add('event_bundle_sequence_id', LongType())\n",
    "             .add('value', DoubleType())\n",
    "             .add('event_trigger_timestamp', StringType())\n",
    "             .add('legacy_event_name', StringType())\n",
    "             .add('parent_component_name', StringType())\n",
    "             .add('component_name', StringType())\n",
    "             .add('content_group', StringType())\n",
    "             .add('content_group_detail', StringType())\n",
    "             .add('market', StringType())\n",
    "             .add('browser_tab_id', StringType())\n",
    "             .add('deeplink', StringType())\n",
    "             .add('page_title', StringType())\n",
    "             .add('page_location', StringType())\n",
    "             .add('session_engaged', StringType())\n",
    "             .add('navigation_target_group', StringType())\n",
    "             .add('shop_language', StringType())\n",
    "             .add('currency', StringType())\n",
    "             .add('initial_flow_id', StringType())\n",
    "             .add('ignore_referrer', StringType())\n",
    "             .add('method',StringType())\n",
    "             .add('firebase_screen',StringType())\n",
    "             .add('firebase_screen_class',StringType())\n",
    "             .add('ga_session_id', LongType())\n",
    "             .add('ga_session_number', LongType())\n",
    "             .add('engagement_time_msec', LongType())\n",
    "             .add('firebase_conversion', LongType())\n",
    "             .add('batch_ordering_id', LongType())\n",
    "             .add('batch_page_id', LongType())\n",
    "             .add('engaged_session_event', LongType())\n",
    "             .add('client_id', StringType())\n",
    "             .add('device_consent_id', StringType())\n",
    "             .add('user_id', StringType())\n",
    "             .add('user_pseudo_id', StringType())\n",
    "             .add('is_active_user', BooleanType())\n",
    "             .add('analytics_storage', StringType())\n",
    "             .add('ads_storage', StringType())\n",
    "             .add('uses_transient_token', StringType())\n",
    "             .add('category', StringType())\n",
    "             .add('mobile_brand_name', StringType())\n",
    "             .add('mobile_model_name', StringType())\n",
    "             .add('mobile_marketing_name', StringType())\n",
    "             .add('operating_system', StringType())\n",
    "             .add('language', StringType())\n",
    "             .add('is_limited_ad_tracking', StringType())\n",
    "             .add('browser', StringType())\n",
    "             .add('browser_version', StringType())\n",
    "             .add('hostname', StringType())\n",
    "             .add('platform', StringType())\n",
    "             .add('id', StringType())\n",
    "             .add('version', StringType())\n",
    "             .add('install_store', StringType())\n",
    "             .add('firebase_app_id', StringType())\n",
    "             .add('install_source', StringType())\n",
    "             .add('city', StringType())\n",
    "             .add('country', StringType())\n",
    "             .add('continent', StringType())\n",
    "             .add('region', StringType())\n",
    "             .add('sub_continent', StringType())\n",
    "             .add('stream_id', StringType())\n",
    "             .add('total_item_quantity', LongType())\n",
    "             .add('purchase_revenue_in_usd', DoubleType())\n",
    "             .add('purchase_revenue', DoubleType())\n",
    "             .add('refund_value_in_usd', DoubleType())\n",
    "             .add('refund_value', DoubleType())\n",
    "             .add('shipping_value_in_usd', DoubleType())\n",
    "             .add('shipping_value', DoubleType())\n",
    "             .add('tax_value_in_usd', DoubleType())\n",
    "             .add('tax_value', DoubleType())\n",
    "             .add('unique_items', LongType())\n",
    "             .add('transaction_id', StringType())\n",
    "             .add('item_id', StringType())\n",
    "             .add('item_name', StringType())\n",
    "             .add('item_brand', StringType())\n",
    "             .add('item_variant', StringType())\n",
    "             .add('item_category', StringType())\n",
    "             .add('price_in_usd', DoubleType())\n",
    "             .add('price', DoubleType())\n",
    "             .add('quantity', LongType())\n",
    "             .add('item_revenue_in_usd', DoubleType())\n",
    "             .add('item_revenue', DoubleType())\n",
    "             .add('item_refund', DoubleType())\n",
    "             .add('coupon', StringType())\n",
    "             .add('affiliation', StringType())\n",
    "             .add('item_flags', StringType())\n",
    "             .add('size_availability', StringType())\n",
    "             .add('last_dt', LongType())\n",
    "             .add('FieldsValueTest', StringType())\n",
    "             .add('RequiredFieldsTest', StringType())\n",
    "             .add('StringFieldsTest', StringType())\n",
    "             .add('IntegerFieldsTest', StringType())\n",
    "             .add('FloatFieldsTest', StringType())\n",
    "             .add('PseudonymizationTest',StringType())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9b49e00-6707-46da-9e48-2ae91df2e3a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Iterate each event and retrieve unvalid rows\n",
    "ga4_unvalid_events = spark.createDataFrame(data = [], schema = GA4_schema)\n",
    "\n",
    "for event in event_list:\n",
    "  ga4_parsed_query = f'''\n",
    "\n",
    "CREATE TEMP FUNCTION IsDate(x STRING) AS \n",
    "(x IS NULL OR SAFE_CAST(x AS DATE) IS NOT NULL);  \n",
    "\n",
    "CREATE TEMP FUNCTION IsString(x STRING) AS \n",
    "(x IS NULL OR SAFE_CAST(x AS STRING) IS NOT NULL);  \n",
    "\n",
    "CREATE TEMP FUNCTION IsInteger(x INT64) AS \n",
    "(x IS NULL OR SAFE_CAST(x AS INT64) IS NOT NULL); \n",
    "\n",
    "CREATE TEMP FUNCTION IsFloat(x FLOAT64) AS \n",
    "(x IS NULL OR SAFE_CAST(x AS FLOAT64) IS NOT NULL);  \n",
    "\n",
    "WITH CTE AS (\n",
    "SELECT DISTINCT\n",
    "         event_name\n",
    "        ,event_date AS dt\n",
    "        ,(SELECT value.double_value FROM UNNEST(event_params) WHERE key = 'value') AS value\n",
    "        ,0 AS last_dt\n",
    "        ,CASE \n",
    "            WHEN platform IS NOT NULL AND platform NOT IN ('WEB','IOS','ANDROID')\n",
    "              THEN 'platform is invalid'\n",
    "            WHEN device.category IS NOT NULL AND device.category NOT IN ('smart tv', 'tablet', 'mobile', 'desktop') \n",
    "              THEN 'device category is invalid'\n",
    "            WHEN LENGTH((SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'market')) > 2 \n",
    "              THEN 'market is longer than 2 letter'\n",
    "            ELSE 'Valid'\n",
    "          END AS FieldsValueTest\n",
    "  FROM `fs-raw-data.analytics_419243363.p_events_*` , UNNEST(items) as items\n",
    "  WHERE _table_suffix between '{startDateBQ}' and '{endDateBQ}'\n",
    "  AND event_name = '{event['event_name']}'\n",
    "  )\n",
    "\n",
    "  SELECT *\n",
    "         ,{event['RequiredFields']}\n",
    "         ,{event['StringFields']}\n",
    "         ,{event['IntegerFields']}\n",
    "         ,{event['FloatFields']}\n",
    "         ,{event['PseudonymizationFields']}\n",
    "  FROM CTE\n",
    "'''\n",
    "\n",
    "  ga4_parsed = (\n",
    "          spark.read.format(\"bigquery\")\n",
    "          .option(\"query\", ga4_parsed_query)\n",
    "          .option(\"materializationDataset\", \"spark_staging_EU\")\n",
    "          .load()\n",
    "      )\n",
    "\n",
    "  # Filter the invalid records\n",
    "  temp_df = ga4_parsed.filter(~f.col('FieldsValueTest').isin('Valid') |\n",
    "                              ~f.col('RequiredFieldsTest').isin('Valid') | \n",
    "                              ~f.col('StringFieldsTest').isin('Valid') |  \n",
    "                              ~f.col('IntegerFieldsTest').isin('Valid') | \n",
    "                              ~f.col('FloatFieldsTest').isin('Valid') | \n",
    "                              ~f.col('PseudonymizationTest').isin('Valid')\n",
    "                              )\n",
    "  ga4_unvalid_events = ga4_unvalid_events.unionAll(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6804f67b-7ad5-4a2d-a54d-35b554062ac3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ga4_unvalid_events.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f61cc5a7-343a-4897-9bbe-65aea0fc9f1f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#####Â Write final data to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdecc106-88f0-40e1-b016-84b8ad96bc7e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "now=datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d403b966-65a4-4364-9701-2e9fe33b26ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to BigQuery dataset table\n",
    "dataset='project_name.datasetname.GA4_unvalid_events' \n",
    "write_proposition='append'\n",
    "\n",
    "ga4_unvalid_events\\\n",
    "    .withColumn('last_executed',f.lit(now))\\\n",
    "    .write\\\n",
    "    .format(\"bigquery\") \\\n",
    "    .mode(write_proposition) \\\n",
    "    .option(\"temporaryGcsBucket\", temporaryGcsBucket) \\\n",
    "    .option(\"table\", f\"{dataset}\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a98bf93-9157-4b23-92c7-b27baaf8de7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set last_dt\n",
    "lastday_query = f\"\"\"\n",
    "                    UPDATE {dataset} \n",
    "                    SET last_dt = 0 \n",
    "                    WHERE 1=1 ;\n",
    "\n",
    "                    UPDATE {dataset}\n",
    "                    SEANT last_dt = 1\n",
    "                    WHERE dt = (SELECT MAX(dt) FROM {dataset})\n",
    "                 \"\"\"\n",
    "\n",
    "with bigquery.Client(credentials=credentials) as bq_client:\n",
    "    job=bq_client.query(lastday_query)\n",
    "    try:\n",
    "        job.result()\n",
    "        print(\"Updated Successfully.\")\n",
    "    except Exception as e:  \n",
    "        print('Error on query data')\n",
    "        print(e)\n",
    "        raise      "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Connect to GA4 and Validate Data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
